- title: General Information
  type: map
  contents:
    - name: Full Name
      value: Swayam Singh
    - name: Email Address
      value: <a href="mailto:singhswayam008@gmail.com">singhswayam008@gmail.com</a>
    - name: Phone Number
      value: +91 9116277756
    - name: Profiles
      links:
        - name: "GitHub"
          link: "https://github.com/SwayamInSync"
        - name: "LinkedIn"
          link: "https://www.linkedin.com/in/swayam-singh-406610213/"
        - name: "Kaggle"
          link: "https://www.kaggle.com/swayamsingh"
        - name: "Google Scholar"
          link: "https://scholar.google.com/citations?user=clLJfm8AAAAJ&hl"
- title: Education
  type: time_table
  contents:
    - title: B.Tech
      institution: University of Allahabad, Uttar Pradesh, India
      year: 2020 - 2024
      description:
        - title: "Relevant Courses:"
          contents:
            - "Gained a comprehensive understanding of key areas through courses like Data Structures, Algorithms, Operating Systems, Big Data, and Software Engineering."
        - title: "Skills Acquired:"
          contents:
            - "Acquired hands-on experience with multiple programming languages, such as Python, and C++, along with proficiency in Data Analysis and Machine Learning."
        - title: "Projects and Research:"
          contents:
            - "Actively involved in projects focused on Machine Learning with Natural Language Processing and Computer Vision."
            - "Developing a comprehensive benchmark for performance-improving code-generation analysis of LLMs."
            - "Building a system to help users try different clothes virtually by just uploading the image."


- title: Work Experience
  type: time_table
  contents:
    - title: Data Science Intern
      institution: Scaler (by Interviewbit)
      year: Aug 2022 - Present
      description:
        - Assisted in the development and deployment of predictive models to minimize infrastructural discrepancies and mitigate potential revenue losses. This proactive approach resulted in a 25% uptick in user engagement.
        -  Developed automation pipelines to auto-pre-process user engagement data and curate monthly reports and insights on personalized recommendations.
        - Utilized statistical analysis and machine learning techniques to identify infrastructure issues and developed mitigation methodologies.
        - Made core contributions to Scaler modules in Data Science and Machine Learning.
    - title: Open Source Research Engineer
      institution: BigCode
      year: Feb 2023 - Present
      description:
        - Contributed significantly to research projects enhancing code generation and large language models for code, and evaluated mathematical reasoning strategies.
        - Collaborated on StarCoder, a 15.5B parameter multi-lingual code-gen model trained on 1 trillion tokens, surpassing OpenAI code-Cushman-001 model.
        - Collaboratively developed OctoPack, leveraging Git commits for instruction tuning and leading to the creation of CommitPack data, Extended HumanEval benchmarks and Octo-duo models.
    - title: Machine Learning Engineer Intern
      institution: dataX.ai (CrowdANALYTX)
      year: May 2022 - Nov 2022
      description:
        - Developed Deep Learning models for business market growth from domains of Computer Vision and Language modelling.
        - Engineered a comprehensive API to automate the conversion of a pretrained model into ONNX format and its seamless deployment via Nvidia Triton Server, culminating in a 12% reduction in VM load.
        - Developed custom CUDA kernels to accelerate 3D image processing for medical scans. Achieved a 2x speedup in segmentation tasks compared to existing CPU-based solutions, thereby improving the overall throughput of the system.
        - Worked on state-of-the-art techniques like DreamBooth, Dichotomous Image Segmentation.
        - Supporting model deployment team in model code analysis and optimizations for DeployX
    - title: Applied Machine Learning Instructor
      institution: Bili Consultancy 
      year: Jan 2022 - April 2022
      description:
        - Mentored final year undergraduate students in their course of Machine Learning.
        - Evaluated and improved the projects developed by students.
- title: Projects
  type: time_table
  contents:
    - title: <a href="https://github.com/SwayamInSync/clothes-virtual-try-on">Virtual Clothing Assistant [PyTorch, flask, OpenCV](100+ ⭐️)</a>
      description: 
        - Allow user to try on different clothes virtually, without going to any trial room.
        - Used <strong>ResNet101</strong> and <strong>UNet</strong> to segment the cloth and model respectively and pose estimation using openpose then final predictions are done using the PyTorch implementation of VITON.
        - <strong>SSIM (Structural Similarity Index Metric)</strong> of 0.895
    - title: <a href="https://github.com/SwayamInSync/MIRA">MIRA - Multimodal Image Reconstruction with Attention *</a>
      description: 
        - MIRA is a multimodal transformer for Text/Image to 3D reconstruction just using single 2D image of object within seconds
        - It uses pre-trained <strong>DINO-V2</strong> as encoder and <strong>custom triplane decoder</strong> that learns to project features on triplane via <strong>cross-attention</strong> and model the relations among the <strong>spatially-structured triplane tokens via self-attention</strong>, <strong>camera features</strong> are modulated within the decoder.
        - Trained by minimizing the difference between the rendered images and ground truth images at novel views, without the need for excessive 3D-aware regularization or delicate hyper-parameter tuning.
    - title: <a href="https://github.com/SwayamInSync/S.E.A.R.C.H">S.E.A.R.C.H (Systematic Engine for Analyzed Retrieval and Contextual Handling)</a>
      description: 
        - S.E.A.R.C.H is a production-ready intelligent open-source agent that can process factual information, and documents across web, providing interactive, personalized assistance.
        - Backed by Zephyr-7B-beta model with efficient post-quantized fine-tuned on <strong>self-rag</strong> dataset using LoRA, to improve cross-domain performance.
        - Production-ready, scalable and efficient Retriever-Augmented Generation system, Retrieving process backed with Keyword extraction + ReRanking.
        - Custom subsequent-query engine allows generating multiple in-context related queries to intelligently cover all possible scenraios.
        - In-built code-interpreter allows efficiently solving reasoning and critical tasks much better than ChatGPT3.5
    - title: <a href="https://github.com/SwayamInSync/3D-Cervical-Spine-Segmentation-and-Multi-Vertebrae-Fracture-Detection">3D Cervical Spine Segmentation and Multi-Vertebrae Fracture Detection</a>
      description: 
        - Developed "3D Cervical Spine Segmentation and Multi-Vertebrae Fracture Detection" to automate cervical spine fracture detection from CT scans, aiming to match radiologist accuracy and ensure timely medical interventions.
        - Leveraged the RSNA 2022's Kaggle Competition dataset; implemented a two-stage model, with the first stage focusing on <strong>3D segmentation</strong> using <strong>EfficientNet + UNet</strong> to create binary masks for the cervical vertebrae (C1-C7).
        - The second stage combined <strong>Convnext + LSTM</strong> for classification. Extracted 15 even slices per vertebrae sample by the z-dimension and added the predicted segmentation mask as an additional channel to distinguish between multiple vertebrae.
        - Created a <strong>3D reconstruction</strong> of spine to visualize the bone and corresponding fracture vertebrae.
        - Achieved a <strong>Multilabel Dice Score</strong> of 0.92 for segmentation and used a <strong>Modified BCE loss</strong> with a score of 0.365 for classification.
    - title: <a href="https://github.com/SwayamInSync/PythonCoder">PythonCoder [PyTorch]</a>
      description: 
        - A custom <strong>60M</strong> params GPT-like casual code generation model trained and evaluated on large Python codebase for 10k steps.
        - <strong>Self-implemented GPT2</strong> architecture using <strong>MultiQueryAttention</strong> allows fast large batch inference and <strong>FlashAttention</strong> allows 3x faster calculation of attention values with <strong>context window of 1024 tokens</strong>
        - Training process leverages the entire context length by concatenating the sequences into a one big chunk, enabling faster training and better consumption of compute resources
    - title: <a href="https://github.com/SwayamInSync/deep-learning/tree/master/Research%20Papers%20implementation/style%20transfer">Image Style Transfer using CNN [PyTorch, Pillow, OpenCV]</a>
      description: 
        - It can impose the texture/style of one image on the other without disturbing the content of the other image.
        - Used pre-trained VGG-19 network to extract the features from multiple convolutional layers for style and content then merged them while maintaining the content and style tradeoff.
    - title: <a href="https://github.com/practice404/Edwin_Lander_RL">Reinforced Edwin Lander [PyTorch, Stablebaselines3, Gym]</a>
      description: 
        - It's a custom Gym environment built to train RL models on the Edwin Lander game to land via following the rules
        - Current model is trained on PPO algorithm and attained the perfect landing score by training up to 1M steps.
    - title: <a href="https://huggingface.co/rootacess/xlm-roberta-base-finetuned">Multilingual Name Entity Recognition [PyTorch, Huggingface]</a>
      description: 
        - XLM-RoBERTa fine-tuned in German, French, and Italian languages enables robust Zero-Shot Classification.
        - It achieves the expected f1-score of 0.8638 on validation set and gives decent f1-scores on low-resource languages.
        - Thoroughly processed and analyzed using a custom Error Analysis pipeline.
        - Ensures reliable classification across multiple languages through meticulous analysis and error handling.
    - title: <a href="https://huggingface.co/spaces/bigcode/Reasoning-with-StarCoder">Reasoning With StarCoder</a>
      description: 
        - User-driven playground for interacting with StarCoder, assessing its reasoning capabilities.
        - Evaluation strategies including PAL, TA, and MathPrompter.
        - Model generates code based on the selected strategy followed by the post-processing of model response then executes it on the server, and displays the result.
        - Leverage the infilling and commit-style of StarCoder to self repair the codes for potential errors
        - Flexibility provided by allowing users to edit the generated code and re-run it for customized solutions.

- title: Research and Publication
  type: list
  contents:
    - Swayam Singh, Niklas Muennighoff, et al., "OctoPack Instruction Tuning Code Large Language Models" arXiv:2308.07124, 2023. <strong><i>Accepted at Instruction Workshop at NeurIPS 2023, ICLR 2024</i></strong>
    - Swayam Singh, Harm de Vries, et al."StarCoder may the source be with you!" arXiv:2305.06161, 2023. <strong><i>Accepted at TMLR (Transactions on Machine Learning Research)</i></strong>

- title: Achievements
  type: time_table
  contents:
    - year: 2024
      items: 
        - 🚀 Our research work "<strong>OctoPack Instruction Tuning Code Large Language Models</strong>" is accepted as the <strong>SPOTLIGHT</strong> at ICLR 2024 (top 5%)
        - 🚀 Top 7% (Bronze medal) in Kaggle’s UBC Ovarian Cancer Subtype Classification and Outlier Detection (UBC-OCEAN) Competition
    - year: 2023
      items: 
        - My project <a href="https://github.com/SwayamInSync/clothes-virtual-try-on" target="_blank"> Clothes Virtual Try On</a> hit 100+ stars on GitHub! 🌟
        - My collaborative research work, "<strong>StarCoder may the source be with you!</strong>" has been accepted at the <strong>TMLR (Transactions on Machine Learning Research)</strong>.
        - 100+ citations of my research work on Google Scholar
        - My collaborative research work, "<strong>OctoPack Instruction Tuning Code Large Language Models</strong>" has been accepted at the <strong>Instruction Workshop @ NeurIPS 2023</strong>.
        - Selected in Amazon ML Summer School 2023, Engaged in advanced ML modules and collaborated with leading Amazon ML Scientists.
    - year: 2022
      items: 
        - Secured Top 3 % global rank in Kaggle's 30 days ML challenge.

- title: SKILLS
  type: list
  contents:
    - <u>Languages:</u> Python, C++, Cuda
    - <u>Frameworks / Libraries:</u> PyTorch, Tensorflow, Huggingface, OpenCV, scikit-learn, Weight & Bias, Docker, AWS, TFX
    - <u>Technical Skills:</u> Machine Learning, Deep Learning, Reinforcement Learning, NLP , Computer Vision, Data Analysis, Data Structures and Algorithms, NeRF, 3D reconstruction, VLM
